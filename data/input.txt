Las redes neuronales profundas (DNN) inspiradas en el comportamiento del cerebro permiten que las computadoras resuelvan tareas cognitivas en las que los humanos sobresalen [1,2]. A falta de explicaciones para tales fenómenos cognitivos, a su vez, los científicos cognitivos han comenzado a utilizar las DNN como modelos para investigar la cognición biológica y sus bases neuronales, creando un importante debate. Más allá de su poder para proporcionar predicciones y explicaciones de los fenómenos cognitivos, las DNN tienen el potencial de contribuir a un uso a menudo ignorado, pero omnipresente y fundamental, de los modelos científicos: la exploración. En los últimos años, las redes neuronales profundas de inspiración neurológica (DNN) han revolucionado la visión por computadora [3] y, posteriormente, otros dominios, como el procesamiento del lenguaje natural [4], el control y la planificación (como juegos, por ejemplo, Atari y Go [5, 6]), y tareas de navegación (como encontrar la ruta más corta en un mapa del metro [7]). Las DNN son modelos computacionales que consisten en considerar muchas unidades de procesamiento simples (similares a las neuronas) que funcionan en paralelo y están dispuestas en capas interconectadas. Las redes neuronales simples constan de una capa de entrada, una capa de salida y en general una capa oculta; cuando se apilan más capas, las redes se llaman profundas [8, 9]. Una DNN aprende a realizar tareas particulares a través del entrenamiento, durante el cual se aprende la fuerza de las conexiones, pesos, entre las unidades. Posteriormente, una red DNN entrenada se utiliza para realizar la misma tarea con patrones novedosos que forman el conjunto de test o generalización. Redes Neuronales Convolucionales (Introducción) La investigación en redes neuronales artificiales comenzó hace casi 80 años [10]. Durante muchos años, no hubo un modelo biológico ampliamente aceptado para redes neuronales asociadas a la visión, hasta que un trabajo experimental aclaró la estructura y función de la corteza visual de los mamíferos [11]. A partir de entonces, las investigaciones teóricas construyeron modelos que guardan similitud con las redes neuronales biológicas [12]. Si bien el progreso teórico continuó con el desarrollo de métodos para la formación de redes, aún no existía un método práctico para la formación de grandes redes. Con el desarrollo de LeNet, por Yann Le Cunn, et al., Se implementó la primera convnet práctica para reconocer dígitos escritos a mano en cheques bancarios [13]. Introducción a los Modelos Computacionales Curso 2021-2022 Grado de Ingeniería Informática en Computación César Hervás-Martínez Pedro A. Gutiérrez Peña 4 Desde que AlexNet se desarrolló y aplicó a la competición de la clasificación de la base de datos ImageNet en 2012 [14], la investigación en redes convolucionales para aplicaciones de aprendizaje profundo ha aumentado exponencialmente. En 2015, el error de clasificación, en esta base de datos, era superior al 5%, esto es, un 6.67%, y se alcanzo con la red GoogLeNet [15], y se redujo a un 3.57%, con la red residual ResNet de Microsoft [16]. En los últimos años, se han desarrollado nuevas arquitecturas de redes neuronales que mejoran las arquitecturas anteriores. Específicamente, analizaremos los módulos primitivos de GoogLeNet, y las redes residuales en ResNet de Microsoft [16]. También, examinaremos las redes neuronales convolucionales (convnets) para el reconocimiento de imágenes, y luego proporcionaremos una explicación de su arquitectura. Igualmente se examinará el papel de varios hiperparámetros de las redes convnet; asi como el problema de cómo dimensionar correctamente una red neuronal, en términos de la cantidad de capas convolucionales y el tamaño de capa. Se presentara un ejemplo para determinar la memoria GPU requerida para entrenar una arquitectura de red definida. Discutiremos el algoritmo de retropropagación del error en el contexto de desarrollos pasados, y recientes, que han mejorado la efectividad del aprendizaje; y brevemente otras técnicas y consideraciones relacionadas con el aprendizaje de la red, como elegir una función de activación y una inicialización adecuada de los pesos de la red. Finalmente, se revisaran los desarrollos recientes en arquitecturas convnet. Una red neuronal convolucional (CNN) es un tipo de red neuronal artificial utilizada en el reconocimiento y procesamiento de imágenes que está específicamente diseñada para procesar datos de píxeles o voxeles. Las redes CNN son potentes procesadores de imágenes, basadas en inteligencia artificial (AI) que utilizan el aprendizaje profundo para realizar tareas tanto generativas como descriptivas, a menudo con algoritmos que incluyen reconocimiento de imágenes y videos, junto con sistemas de recomendación y procesamiento de lenguaje natural (PNL). Una red neuronal es un sistema de hardware y/o software de modelado que simula las operaciones de las neuronas del cerebro humano. Las redes neuronales tradicionales no son ideales para el procesamiento de imágenes y deben utilizarse con imágenes de resolución reducida. Las CNN tienen sus "neuronas" dispuestas como las del lóbulo frontal, el área responsable del procesamiento de estímulos visuales en humanos y otros animales. Las capas de neuronas están dispuestas de tal manera que cubren todo el campo visual, evitando el problema de procesamiento poco sistemático de imágenes de las redes neuronales tradicionales. Introducción a los Modelos Computacionales Curso 2021-2022 Grado de Ingeniería Informática en Computación César Hervás-Martínez Pedro A. Gutiérrez Peña 5 Una CNN usa un sistema muy parecido a un perceptrón multicapa que ha sido diseñado para reducir los requisitos de procesamiento. Las capas de una CNN consisten en una capa de entrada, una capa de salida y unas capas ocultas que incluye múltiples capas convolucionales, capas de agrupación, capas completamente conectadas y capas de normalización. La eliminación de las limitaciones y el aumento de la eficiencia para el procesamiento de imágenes dan como resultado un sistema mucho más efectivo e intuitivo para el procesamiento de imágenes y el procesamiento del lenguaje natural. 
Arquitectura de una "convnet" Hasta que no se pudieron realizar operaciones matriciales en paralelo en las unidades de procesamiento gráfico (GPU) en computadoras de escritorio, no fue posible desarrollar redes más grandes para clasificar imágenes con un gran número de clases, por ejemplo tomadas de ImageNet [17]. Las redes neuronales de grandes dimensiones tienen la capacidad de emular el comportamiento de funciones arbitrarias, complejas y no lineales. Cuando se entrenan de manera efectiva, las funciones emuladas por una convnet tienen la capacidad de mapear datos de imágenes complejas y de alta dimensión en un espacio dimensional mucho más bajo de categorías definidas finitas, que consta de cientos o miles de clases de objetos. Así, la distinción entre categorías puede ser mejorada, por ejemplo, un gato, en lugar de un lince (ver Fig 1). Figura 1: Un gato puede, en muchos casos, no ser discernible con facilidad de un lince Las redes también se utilizan, entre otras tareas, para la detección de objetos, el reconocimiento de escenas, la estimación de posturas humanas, la generación de subtítulos de video, el reconocimiento de voz, la traducción de idiomas, etc. La idea de usar filtros locales (en lugar de capas totalmente conectadas) en una convnet surgió primero de la observación de que, en imágenes, no hay una estructura significativa en escalas de distancia grande. "Más grande" es un término relativo aquí, que depende de la composición de la imagen. A grandes distancias, los píxeles están relacionados al azar. Pero, a distancias más cortas, se correlacionan sus valores. Introducción a los Modelos Computacionales Curso 2021-2022 Grado de Ingeniería Informática en Computación César Hervás-Martínez Pedro A. Gutiérrez Peña 6 Esto indica que se puede encontrar una estructura significativa dentro de los parches de las imágenes locales. Esto no es sorprendente, ya que los objetos están definidos por su estructura local y no por lo que está lejos de ellos. Un jarrón, por ejemplo, puede ser definido por sus contornos. Los píxeles alejados del jarrón no proporcionan más información sobre el jarrón, a menos que por coincidencia siempre se coloque al lado de un cubo pequeño. Con tal conjunto de imágenes, un clasificador de imágenes entrenado para reconocer jarrones también puede usar elementos del cubo para determinar si hay un jarrón en la imagen. De hecho, antes del entrenamiento, no está claro qué tipo de características seleccionará una red para mejorar el reconocimiento. Una red entrenada por [18], por ejemplo, podría reconocer los coches de carreras, en parte, al desarrollar detectores para el contenido de texto de las pegatinas publicitarias pegadas a los lados de ellos, lo que no es necesariamente algo que uno asociaría de inmediato con un automóvil. Pero como es una característica distintiva de los coches de carreras, la red aprendió a reconocer el texto de los anuncios, y luego usó esta característica, en una representación distribuida, para activar la salida de red que indica la categoría de cada coche de carreras, y no otro tipo de coche. La información estructural contenida en regiones locales de las imágenes motivó el uso de conexiones de tipo parches entre capas, en lugar de conexiones completas. Esto es lo mismo que usar conexiones donde cada peso es cero, excepto, posiblemente, para pesos dentro de alguna región del parche (filtro o kernel). Los ceros representan el hecho de que la información fuera del parche no determina nada sobre la estructura presente en el área local del filtro. Solo las neuronas dentro de un (cuadrado) parche/ filtro/ kernel estarían completamente conectadas a las neuronas individuales en la siguiente capa (ver Figura 2). Al reducir el número de conexiones, se reduce el número de pesos o conexiones de la red. Esto reduce el tiempo de computación, tanto en entrenamiento como durante la generalización. Además, los filtros mantienen los mismos pesos, ya que convolucionan en varias posiciones formando un mapa de características. Esto significa que un filtro está utilizando los mismos pesos para detectar el mismo tipo de entidad en varias ubicaciones de un mapa de características. Esto ayuda a reducir aún más el número de parámetros y también ayuda a prevenir el sobre-entrenamiento de la red en el conjunto de test. El uso de filtros locales (conexiones de parches) en lugar de conexiones completas también reduce el sobre-entrenamiento.